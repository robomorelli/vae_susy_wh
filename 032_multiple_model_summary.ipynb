{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = 'model_dependent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dictionaries for the following signal injection will be updated: ['650_300']\n"
     ]
    }
   ],
   "source": [
    "if analysis == 'model_dependent':\n",
    "    sig_names = os.listdir(model_dep_results_multiple)\n",
    "    print('the dictionaries for the following signal injection will be updated: {}'.format(sig_names))\n",
    "    path_results = model_dep_results_multiple\n",
    "\n",
    "elif analysis == 'model_independent':\n",
    "    sig_names = os.listdir(model_results_multiple)\n",
    "    print('the dictionaries for the following signal injection will be updated: {}'.format(sig_names))\n",
    "    path_results = model_results_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_results/model_dependent/multiple_train//650_300/0_1_3_ft_3/w_5_10_10 number 0\n",
      "model_results/model_dependent/multiple_train//650_300/0_1_3_ft_3/w_5_5_10 number 1\n"
     ]
    }
   ],
   "source": [
    "path_append =[]\n",
    "idx = 0\n",
    "for s_n in sig_names:\n",
    "    fold_names = os.listdir(path_results + '/' + s_n)\n",
    "    for fold_name in fold_names:  \n",
    "        fold_name_path = path_results + '/' + s_n + '/' + fold_name\n",
    "        try:\n",
    "            weights_names = os.listdir(fold_name_path)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        for i, weights_name in enumerate(weights_names):  \n",
    "\n",
    "            path = fold_name_path + '/' + weights_name\n",
    "            filenames = os.listdir(path)\n",
    "            names_csv = [name  for name in filenames if name.split('.')[-1]=='csv']\n",
    "\n",
    "    #         ###CHECK HOSTNAME\n",
    "    #         host = directory\n",
    "            header = True\n",
    "            total = []\n",
    "            \n",
    "            for ix, n in enumerate(names_csv):\n",
    "                if 'summary' not in n:\n",
    "                    df = pd.read_csv(path + '/' + n)\n",
    "\n",
    "                    val_loss = df['val_loss'].min()\n",
    "                    KL_loss = df['val_KL_loss'].min()\n",
    "    #                 metric =  df['val_RecoNLL_metric'].min()\n",
    "                    model_num = n.split('.')[0].split('_')[-1]\n",
    "                    epochs = len(df)\n",
    "\n",
    "                    total.append([val_loss,KL_loss, epochs, model_num])\n",
    "\n",
    "            columns = ['val_loss', 'val_KL_loss','epochs','model_num']\n",
    "            analysis = pd.DataFrame(total, columns=columns)\n",
    "\n",
    "            print(path, 'number', idx)\n",
    "            idx += 1\n",
    "           \n",
    "            path_append.append(path.split('//')[1] + '/' + 'result_summary.csv')\n",
    "\n",
    "            analysis.to_csv(path  + '/' + 'result_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650_300/0_1_3_ft_3/w_5_5_10/result_summary.csv\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "df = pd.read_csv(model_dep_results_multiple+path_append[num])\n",
    "print(path_append[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   val_loss  val_KL_loss  epochs  model_num\n",
      "0           0  19.591674      8.40283     330          0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dictionaries for the following models will be updated: ['0_1_3_ft_3']\n"
     ]
    }
   ],
   "source": [
    "fold_names = os.listdir(model_results_multiple)\n",
    "print('the dictionaries for the following models will be updated: {}'.format(fold_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_5_10_10\n",
      "model_results/model_independent/multiple_train//0_1_3_ft_3/w_5_10_10\n"
     ]
    }
   ],
   "source": [
    "path_append = []\n",
    "for fold_name in fold_names:  \n",
    "    fold_name_path = model_results_multiple + '/' + fold_name\n",
    "    weights_names = os.listdir(fold_name_path)\n",
    "\n",
    "    for weights_name in weights_names:  \n",
    "        print(weights_name)\n",
    "        path = fold_name_path + '/' + weights_name\n",
    "        filenames = os.listdir(path)\n",
    "        names_csv = [name  for name in filenames if name.split('.')[-1]=='csv']\n",
    "\n",
    "#         ###CHECK HOSTNAME\n",
    "#         host = directory\n",
    "        header = True\n",
    "        total = []\n",
    "\n",
    "        for ix, n in enumerate(names_csv):\n",
    "            if 'summary' not in n:\n",
    "                df = pd.read_csv(path + '/' + n)\n",
    "\n",
    "                val_loss = df['val_loss'].min()\n",
    "                KL_loss = df['val_KL_loss'].min()\n",
    "#                 metric =  df['val_RecoNLL_metric'].min()\n",
    "                model_num = n.split('.')[0].split('_')[-1]\n",
    "                epochs = len(df)\n",
    "\n",
    "                total.append([val_loss,KL_loss, epochs, model_num])\n",
    "\n",
    "        columns = ['val_loss', 'val_KL_loss','epochs','model_num']\n",
    "        analysis = pd.DataFrame(total, columns=columns)\n",
    "\n",
    "        print(path)\n",
    "        path_append.append(path.split('//')[1] + '/' + 'result_summary.csv')\n",
    "\n",
    "        analysis.to_csv(path  + '/' + 'result_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_results/model_independent/multiple_train/0_1_3_ft_3/w_5_10_10/result_summary.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(model_results_multiple+path_append[0])\n",
    "print(model_results_multiple+path_append[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_KL_loss</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.845371</td>\n",
       "      <td>8.765312</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   val_loss  val_KL_loss  epochs  model_num\n",
       "0           0  15.845371     8.765312     322          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(2050.0)/np.sqrt(3)\n",
    "\n",
    "err1 = np.sqrt(2000)\n",
    "err2 = np.sqrt(2100)\n",
    "err3 = np.sqrt(2050)\n",
    "\n",
    "(1/3)*np.sqrt(err1**2 + err2**2 + err3**2)\n",
    "\n",
    "[x for x in '1234321'][:3]==[x for x in '1234321'][::-1][:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
